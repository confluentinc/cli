// Code generated by protoc-gen-gogo. DO NOT EDIT.
// source: kafka.proto

/*
Package connect is a generated protocol buffer package.

It is generated from these files:
	kafka.proto

It has these top-level messages:
*/
package connect

import proto "github.com/gogo/protobuf/proto"
import fmt "fmt"
import math "math"
import kafka_scheduler_v1 "github.com/confluentinc/cc-structs/kafka/scheduler/v1"

import context "golang.org/x/net/context"
import grpc "google.golang.org/grpc"

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.GoGoProtoPackageIsVersion2 // please upgrade the proto package

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion4

// Client API for Kafka service

type KafkaClient interface {
	List(ctx context.Context, in *kafka_scheduler_v1.GetKafkaClustersRequest, opts ...grpc.CallOption) (*kafka_scheduler_v1.GetKafkaClustersReply, error)
	Describe(ctx context.Context, in *kafka_scheduler_v1.GetKafkaClusterRequest, opts ...grpc.CallOption) (*kafka_scheduler_v1.GetKafkaClusterReply, error)
}

type kafkaClient struct {
	cc *grpc.ClientConn
}

func NewKafkaClient(cc *grpc.ClientConn) KafkaClient {
	return &kafkaClient{cc}
}

func (c *kafkaClient) List(ctx context.Context, in *kafka_scheduler_v1.GetKafkaClustersRequest, opts ...grpc.CallOption) (*kafka_scheduler_v1.GetKafkaClustersReply, error) {
	out := new(kafka_scheduler_v1.GetKafkaClustersReply)
	err := grpc.Invoke(ctx, "/connect.Kafka/List", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kafkaClient) Describe(ctx context.Context, in *kafka_scheduler_v1.GetKafkaClusterRequest, opts ...grpc.CallOption) (*kafka_scheduler_v1.GetKafkaClusterReply, error) {
	out := new(kafka_scheduler_v1.GetKafkaClusterReply)
	err := grpc.Invoke(ctx, "/connect.Kafka/Describe", in, out, c.cc, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// Server API for Kafka service

type KafkaServer interface {
	List(context.Context, *kafka_scheduler_v1.GetKafkaClustersRequest) (*kafka_scheduler_v1.GetKafkaClustersReply, error)
	Describe(context.Context, *kafka_scheduler_v1.GetKafkaClusterRequest) (*kafka_scheduler_v1.GetKafkaClusterReply, error)
}

func RegisterKafkaServer(s *grpc.Server, srv KafkaServer) {
	s.RegisterService(&_Kafka_serviceDesc, srv)
}

func _Kafka_List_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(kafka_scheduler_v1.GetKafkaClustersRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaServer).List(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/connect.Kafka/List",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaServer).List(ctx, req.(*kafka_scheduler_v1.GetKafkaClustersRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _Kafka_Describe_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(kafka_scheduler_v1.GetKafkaClusterRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaServer).Describe(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/connect.Kafka/Describe",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaServer).Describe(ctx, req.(*kafka_scheduler_v1.GetKafkaClusterRequest))
	}
	return interceptor(ctx, in, info, handler)
}

var _Kafka_serviceDesc = grpc.ServiceDesc{
	ServiceName: "connect.Kafka",
	HandlerType: (*KafkaServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "List",
			Handler:    _Kafka_List_Handler,
		},
		{
			MethodName: "Describe",
			Handler:    _Kafka_Describe_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "kafka.proto",
}

func init() { proto.RegisterFile("kafka.proto", fileDescriptorKafka) }

var fileDescriptorKafka = []byte{
	// 152 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xe2, 0xe2, 0xce, 0x4e, 0x4c, 0xcb,
	0x4e, 0xd4, 0x2b, 0x28, 0xca, 0x2f, 0xc9, 0x17, 0x62, 0x4f, 0xce, 0xcf, 0xcb, 0x4b, 0x4d, 0x2e,
	0x91, 0x52, 0x02, 0x8b, 0xea, 0x17, 0x27, 0x67, 0xa4, 0xa6, 0x94, 0xe6, 0xa4, 0x16, 0xe9, 0x97,
	0x19, 0x22, 0x38, 0x10, 0xc5, 0x46, 0x67, 0x19, 0xb9, 0x58, 0xbd, 0x41, 0xca, 0x84, 0x12, 0xb8,
	0x58, 0x7c, 0x32, 0x8b, 0x4b, 0x84, 0xb4, 0xf5, 0x20, 0x86, 0x21, 0x54, 0x96, 0x19, 0xea, 0xb9,
	0xa7, 0x96, 0x80, 0x55, 0x39, 0xe7, 0x94, 0x16, 0x97, 0xa4, 0x16, 0x15, 0x07, 0xa5, 0x16, 0x96,
	0xa6, 0x16, 0x97, 0x48, 0x69, 0x12, 0xa7, 0xb8, 0x20, 0xa7, 0x52, 0x89, 0x41, 0x28, 0x89, 0x8b,
	0xc3, 0x25, 0xb5, 0x38, 0xb9, 0x28, 0x33, 0x29, 0x55, 0x48, 0x8b, 0x08, 0x8d, 0x30, 0x4b, 0x34,
	0x88, 0x52, 0x0b, 0xb6, 0x23, 0x89, 0x0d, 0xec, 0x2d, 0x63, 0x40, 0x00, 0x00, 0x00, 0xff, 0xff,
	0xa6, 0x33, 0xe4, 0xec, 0x12, 0x01, 0x00, 0x00,
}

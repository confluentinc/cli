// Code generated by protoc-gen-gogo. DO NOT EDIT.
// source: kafka.proto

package kafka

import proto "github.com/gogo/protobuf/proto"
import fmt "fmt"
import math "math"
import v1 "github.com/confluentinc/cc-structs/kafka/scheduler/v1"

import (
	context "golang.org/x/net/context"
	grpc "google.golang.org/grpc"
)

// Reference imports to suppress errors if they are not otherwise used.
var _ = proto.Marshal
var _ = fmt.Errorf
var _ = math.Inf

// This is a compile-time assertion to ensure that this generated file
// is compatible with the proto package it is being compiled against.
// A compilation error at this line likely means your copy of the
// proto package needs to be updated.
const _ = proto.GoGoProtoPackageIsVersion2 // please upgrade the proto package

// KafkaTopicConfigSource wraps ConfigEntry
// Apache Kafka reference
// https://github.com/confluentinc/cc-kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/admin/ConfigEntry.java
type KafkaTopicConfigSource int32

const (
	KafkaTopicConfigSource_DYNAMIC_TOPIC_CONFIG          KafkaTopicConfigSource = 0
	KafkaTopicConfigSource_DYNAMIC_BROKER_CONFIG         KafkaTopicConfigSource = 1
	KafkaTopicConfigSource_DYNAMIC_DEFAULT_BROKER_CONFIG KafkaTopicConfigSource = 2
	KafkaTopicConfigSource_STATIC_BROKER_CONFIG          KafkaTopicConfigSource = 3
	KafkaTopicConfigSource_DEFAULT_CONFIG                KafkaTopicConfigSource = 4
	KafkaTopicConfigSource_UNKNOWN                       KafkaTopicConfigSource = 5
)

var KafkaTopicConfigSource_name = map[int32]string{
	0: "DYNAMIC_TOPIC_CONFIG",
	1: "DYNAMIC_BROKER_CONFIG",
	2: "DYNAMIC_DEFAULT_BROKER_CONFIG",
	3: "STATIC_BROKER_CONFIG",
	4: "DEFAULT_CONFIG",
	5: "UNKNOWN",
}
var KafkaTopicConfigSource_value = map[string]int32{
	"DYNAMIC_TOPIC_CONFIG":          0,
	"DYNAMIC_BROKER_CONFIG":         1,
	"DYNAMIC_DEFAULT_BROKER_CONFIG": 2,
	"STATIC_BROKER_CONFIG":          3,
	"DEFAULT_CONFIG":                4,
	"UNKNOWN":                       5,
}

func (x KafkaTopicConfigSource) String() string {
	return proto.EnumName(KafkaTopicConfigSource_name, int32(x))
}
func (KafkaTopicConfigSource) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{0}
}

// FilterType extracts the filter-specific PatternTypes from it's Java counterpart
type AccessControlEntryConfig_FilterType int32

const (
	AccessControlEntryConfig_ANY AccessControlEntryConfig_FilterType = 0
)

var AccessControlEntryConfig_FilterType_name = map[int32]string{
	0: "ANY",
}
var AccessControlEntryConfig_FilterType_value = map[string]int32{
	"ANY": 0,
}

func (x AccessControlEntryConfig_FilterType) String() string {
	return proto.EnumName(AccessControlEntryConfig_FilterType_name, int32(x))
}
func (AccessControlEntryConfig_FilterType) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{0, 0}
}

// Apache Kafka reference
// https://github.com/confluentinc/cc-kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/acl/AclPermissionType.java
type AccessControlEntryConfig_ACLPermissionType int32

const (
	AccessControlEntryConfig_ALLOW AccessControlEntryConfig_ACLPermissionType = 0
	AccessControlEntryConfig_DENY  AccessControlEntryConfig_ACLPermissionType = 1
)

var AccessControlEntryConfig_ACLPermissionType_name = map[int32]string{
	0: "ALLOW",
	1: "DENY",
}
var AccessControlEntryConfig_ACLPermissionType_value = map[string]int32{
	"ALLOW": 0,
	"DENY":  1,
}

func (x AccessControlEntryConfig_ACLPermissionType) String() string {
	return proto.EnumName(AccessControlEntryConfig_ACLPermissionType_name, int32(x))
}
func (AccessControlEntryConfig_ACLPermissionType) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{0, 1}
}

// Apache Kafka reference
// https://github.com/confluentinc/cc-kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/acl/AclOperation.java
type AccessControlEntryConfig_ACLOperation int32

const (
	AccessControlEntryConfig_ALL              AccessControlEntryConfig_ACLOperation = 0
	AccessControlEntryConfig_READ             AccessControlEntryConfig_ACLOperation = 1
	AccessControlEntryConfig_WRITE            AccessControlEntryConfig_ACLOperation = 2
	AccessControlEntryConfig_CREATE           AccessControlEntryConfig_ACLOperation = 3
	AccessControlEntryConfig_DELETE           AccessControlEntryConfig_ACLOperation = 4
	AccessControlEntryConfig_ALTER            AccessControlEntryConfig_ACLOperation = 5
	AccessControlEntryConfig_DESCRIBE         AccessControlEntryConfig_ACLOperation = 6
	AccessControlEntryConfig_CLUSTER_ACTION   AccessControlEntryConfig_ACLOperation = 7
	AccessControlEntryConfig_DESCRIBE_CONFIGS AccessControlEntryConfig_ACLOperation = 8
	AccessControlEntryConfig_ALTER_CONFIGS    AccessControlEntryConfig_ACLOperation = 9
	AccessControlEntryConfig_IDEMPOTENT_WRITE AccessControlEntryConfig_ACLOperation = 10
)

var AccessControlEntryConfig_ACLOperation_name = map[int32]string{
	0:  "ALL",
	1:  "READ",
	2:  "WRITE",
	3:  "CREATE",
	4:  "DELETE",
	5:  "ALTER",
	6:  "DESCRIBE",
	7:  "CLUSTER_ACTION",
	8:  "DESCRIBE_CONFIGS",
	9:  "ALTER_CONFIGS",
	10: "IDEMPOTENT_WRITE",
}
var AccessControlEntryConfig_ACLOperation_value = map[string]int32{
	"ALL":              0,
	"READ":             1,
	"WRITE":            2,
	"CREATE":           3,
	"DELETE":           4,
	"ALTER":            5,
	"DESCRIBE":         6,
	"CLUSTER_ACTION":   7,
	"DESCRIBE_CONFIGS": 8,
	"ALTER_CONFIGS":    9,
	"IDEMPOTENT_WRITE": 10,
}

func (x AccessControlEntryConfig_ACLOperation) String() string {
	return proto.EnumName(AccessControlEntryConfig_ACLOperation_name, int32(x))
}
func (AccessControlEntryConfig_ACLOperation) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{0, 2}
}

// FilterType extracts the filter-specific PatternTypes from it's Java counterpart
type ResourcePatternConfig_FilterType int32

const (
	ResourcePatternConfig_ANY   ResourcePatternConfig_FilterType = 0
	ResourcePatternConfig_MATCH ResourcePatternConfig_FilterType = 1
)

var ResourcePatternConfig_FilterType_name = map[int32]string{
	0: "ANY",
	1: "MATCH",
}
var ResourcePatternConfig_FilterType_value = map[string]int32{
	"ANY":   0,
	"MATCH": 1,
}

func (x ResourcePatternConfig_FilterType) String() string {
	return proto.EnumName(ResourcePatternConfig_FilterType_name, int32(x))
}
func (ResourcePatternConfig_FilterType) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{1, 0}
}

// Apache Kafka reference
// https://github.com/confluentinc/cc-kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/resource/ResourceType.java
type ResourcePatternConfig_ResourceType int32

const (
	ResourcePatternConfig_TOPIC            ResourcePatternConfig_ResourceType = 0
	ResourcePatternConfig_GROUP            ResourcePatternConfig_ResourceType = 1
	ResourcePatternConfig_CLUSTER          ResourcePatternConfig_ResourceType = 2
	ResourcePatternConfig_TRANSACTIONAL_ID ResourcePatternConfig_ResourceType = 3
)

var ResourcePatternConfig_ResourceType_name = map[int32]string{
	0: "TOPIC",
	1: "GROUP",
	2: "CLUSTER",
	3: "TRANSACTIONAL_ID",
}
var ResourcePatternConfig_ResourceType_value = map[string]int32{
	"TOPIC":            0,
	"GROUP":            1,
	"CLUSTER":          2,
	"TRANSACTIONAL_ID": 3,
}

func (x ResourcePatternConfig_ResourceType) String() string {
	return proto.EnumName(ResourcePatternConfig_ResourceType_name, int32(x))
}
func (ResourcePatternConfig_ResourceType) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{1, 1}
}

// Apache Kafka reference
// https://github.com/confluentinc/cc-kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/resource/PatternType.java
type ResourcePatternConfig_PatternType int32

const (
	ResourcePatternConfig_LITERAL  ResourcePatternConfig_PatternType = 0
	ResourcePatternConfig_PREFIXED ResourcePatternConfig_PatternType = 1
)

var ResourcePatternConfig_PatternType_name = map[int32]string{
	0: "LITERAL",
	1: "PREFIXED",
}
var ResourcePatternConfig_PatternType_value = map[string]int32{
	"LITERAL":  0,
	"PREFIXED": 1,
}

func (x ResourcePatternConfig_PatternType) String() string {
	return proto.EnumName(ResourcePatternConfig_PatternType_name, int32(x))
}
func (ResourcePatternConfig_PatternType) EnumDescriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{1, 2}
}

// AccessControlEntryConfig wraps AccessControlEntry
// Apache Kafka reference
// https://github.com/confluen  tinc/cc-kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/acl/AccessControlEntry.java
type AccessControlEntryConfig struct {
	Principal            string   `protobuf:"bytes,1,opt,name=principal,proto3" json:"principal,omitempty"`
	Operation            string   `protobuf:"bytes,2,opt,name=operation,proto3" json:"operation,omitempty"`
	Host                 string   `protobuf:"bytes,3,opt,name=host,proto3" json:"host,omitempty"`
	PermissionType       string   `protobuf:"bytes,4,opt,name=permissionType,proto3" json:"permissionType,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *AccessControlEntryConfig) Reset()         { *m = AccessControlEntryConfig{} }
func (m *AccessControlEntryConfig) String() string { return proto.CompactTextString(m) }
func (*AccessControlEntryConfig) ProtoMessage()    {}
func (*AccessControlEntryConfig) Descriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{0}
}
func (m *AccessControlEntryConfig) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_AccessControlEntryConfig.Unmarshal(m, b)
}
func (m *AccessControlEntryConfig) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_AccessControlEntryConfig.Marshal(b, m, deterministic)
}
func (dst *AccessControlEntryConfig) XXX_Merge(src proto.Message) {
	xxx_messageInfo_AccessControlEntryConfig.Merge(dst, src)
}
func (m *AccessControlEntryConfig) XXX_Size() int {
	return xxx_messageInfo_AccessControlEntryConfig.Size(m)
}
func (m *AccessControlEntryConfig) XXX_DiscardUnknown() {
	xxx_messageInfo_AccessControlEntryConfig.DiscardUnknown(m)
}

var xxx_messageInfo_AccessControlEntryConfig proto.InternalMessageInfo

func (m *AccessControlEntryConfig) GetPrincipal() string {
	if m != nil {
		return m.Principal
	}
	return ""
}

func (m *AccessControlEntryConfig) GetOperation() string {
	if m != nil {
		return m.Operation
	}
	return ""
}

func (m *AccessControlEntryConfig) GetHost() string {
	if m != nil {
		return m.Host
	}
	return ""
}

func (m *AccessControlEntryConfig) GetPermissionType() string {
	if m != nil {
		return m.PermissionType
	}
	return ""
}

// ResourcePatternConfig wraps ResroucePattern
// Apache Kafka reference
// https://github.com/confluentinc/cc-kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/resource/ResourcePattern.java
type ResourcePatternConfig struct {
	ResourceType         string   `protobuf:"bytes,1,opt,name=resourceType,proto3" json:"resourceType,omitempty"`
	Name                 string   `protobuf:"bytes,2,opt,name=name,proto3" json:"name,omitempty"`
	PatternType          string   `protobuf:"bytes,3,opt,name=patternType,proto3" json:"patternType,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *ResourcePatternConfig) Reset()         { *m = ResourcePatternConfig{} }
func (m *ResourcePatternConfig) String() string { return proto.CompactTextString(m) }
func (*ResourcePatternConfig) ProtoMessage()    {}
func (*ResourcePatternConfig) Descriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{1}
}
func (m *ResourcePatternConfig) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_ResourcePatternConfig.Unmarshal(m, b)
}
func (m *ResourcePatternConfig) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_ResourcePatternConfig.Marshal(b, m, deterministic)
}
func (dst *ResourcePatternConfig) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ResourcePatternConfig.Merge(dst, src)
}
func (m *ResourcePatternConfig) XXX_Size() int {
	return xxx_messageInfo_ResourcePatternConfig.Size(m)
}
func (m *ResourcePatternConfig) XXX_DiscardUnknown() {
	xxx_messageInfo_ResourcePatternConfig.DiscardUnknown(m)
}

var xxx_messageInfo_ResourcePatternConfig proto.InternalMessageInfo

func (m *ResourcePatternConfig) GetResourceType() string {
	if m != nil {
		return m.ResourceType
	}
	return ""
}

func (m *ResourcePatternConfig) GetName() string {
	if m != nil {
		return m.Name
	}
	return ""
}

func (m *ResourcePatternConfig) GetPatternType() string {
	if m != nil {
		return m.PatternType
	}
	return ""
}

// ACLSpec wraps an AclBinding
// Apache Kafka reference
// https://github.com/confluentinc/cc-kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/acl/AclBinding.java
type ACLSpec struct {
	Pattern              *ResourcePatternConfig    `protobuf:"bytes,1,opt,name=pattern" json:"pattern,omitempty"`
	Entry                *AccessControlEntryConfig `protobuf:"bytes,2,opt,name=entry" json:"entry,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                  `json:"-"`
	XXX_unrecognized     []byte                    `json:"-"`
	XXX_sizecache        int32                     `json:"-"`
}

func (m *ACLSpec) Reset()         { *m = ACLSpec{} }
func (m *ACLSpec) String() string { return proto.CompactTextString(m) }
func (*ACLSpec) ProtoMessage()    {}
func (*ACLSpec) Descriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{2}
}
func (m *ACLSpec) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_ACLSpec.Unmarshal(m, b)
}
func (m *ACLSpec) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_ACLSpec.Marshal(b, m, deterministic)
}
func (dst *ACLSpec) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ACLSpec.Merge(dst, src)
}
func (m *ACLSpec) XXX_Size() int {
	return xxx_messageInfo_ACLSpec.Size(m)
}
func (m *ACLSpec) XXX_DiscardUnknown() {
	xxx_messageInfo_ACLSpec.DiscardUnknown(m)
}

var xxx_messageInfo_ACLSpec proto.InternalMessageInfo

func (m *ACLSpec) GetPattern() *ResourcePatternConfig {
	if m != nil {
		return m.Pattern
	}
	return nil
}

func (m *ACLSpec) GetEntry() *AccessControlEntryConfig {
	if m != nil {
		return m.Entry
	}
	return nil
}

// KafkaAPIACLFilterRequest wraps an AclBindingFilter
// Apache Kafka reference
// https://github.com/confluentinc/cc-kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/acl/AclBindingFilter.java
type ACLFilter struct {
	PatternFilter        *ResourcePatternConfig    `protobuf:"bytes,1,opt,name=patternFilter" json:"patternFilter,omitempty"`
	EntryFilter          *AccessControlEntryConfig `protobuf:"bytes,2,opt,name=entryFilter" json:"entryFilter,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                  `json:"-"`
	XXX_unrecognized     []byte                    `json:"-"`
	XXX_sizecache        int32                     `json:"-"`
}

func (m *ACLFilter) Reset()         { *m = ACLFilter{} }
func (m *ACLFilter) String() string { return proto.CompactTextString(m) }
func (*ACLFilter) ProtoMessage()    {}
func (*ACLFilter) Descriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{3}
}
func (m *ACLFilter) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_ACLFilter.Unmarshal(m, b)
}
func (m *ACLFilter) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_ACLFilter.Marshal(b, m, deterministic)
}
func (dst *ACLFilter) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ACLFilter.Merge(dst, src)
}
func (m *ACLFilter) XXX_Size() int {
	return xxx_messageInfo_ACLFilter.Size(m)
}
func (m *ACLFilter) XXX_DiscardUnknown() {
	xxx_messageInfo_ACLFilter.DiscardUnknown(m)
}

var xxx_messageInfo_ACLFilter proto.InternalMessageInfo

func (m *ACLFilter) GetPatternFilter() *ResourcePatternConfig {
	if m != nil {
		return m.PatternFilter
	}
	return nil
}

func (m *ACLFilter) GetEntryFilter() *AccessControlEntryConfig {
	if m != nil {
		return m.EntryFilter
	}
	return nil
}

// KafkaAPIACLFilterResponse returns an array of AclBinding objects
type KafkaAPIACLFilterReply struct {
	Results              []*ACLSpec `protobuf:"bytes,1,rep,name=results" json:"results,omitempty"`
	XXX_NoUnkeyedLiteral struct{}   `json:"-"`
	XXX_unrecognized     []byte     `json:"-"`
	XXX_sizecache        int32      `json:"-"`
}

func (m *KafkaAPIACLFilterReply) Reset()         { *m = KafkaAPIACLFilterReply{} }
func (m *KafkaAPIACLFilterReply) String() string { return proto.CompactTextString(m) }
func (*KafkaAPIACLFilterReply) ProtoMessage()    {}
func (*KafkaAPIACLFilterReply) Descriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{4}
}
func (m *KafkaAPIACLFilterReply) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_KafkaAPIACLFilterReply.Unmarshal(m, b)
}
func (m *KafkaAPIACLFilterReply) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_KafkaAPIACLFilterReply.Marshal(b, m, deterministic)
}
func (dst *KafkaAPIACLFilterReply) XXX_Merge(src proto.Message) {
	xxx_messageInfo_KafkaAPIACLFilterReply.Merge(dst, src)
}
func (m *KafkaAPIACLFilterReply) XXX_Size() int {
	return xxx_messageInfo_KafkaAPIACLFilterReply.Size(m)
}
func (m *KafkaAPIACLFilterReply) XXX_DiscardUnknown() {
	xxx_messageInfo_KafkaAPIACLFilterReply.DiscardUnknown(m)
}

var xxx_messageInfo_KafkaAPIACLFilterReply proto.InternalMessageInfo

func (m *KafkaAPIACLFilterReply) GetResults() []*ACLSpec {
	if m != nil {
		return m.Results
	}
	return nil
}

// KafkaAPIResponse represents a generic response to the KafkaAPI requester caller
type KafkaAPIResponse struct {
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *KafkaAPIResponse) Reset()         { *m = KafkaAPIResponse{} }
func (m *KafkaAPIResponse) String() string { return proto.CompactTextString(m) }
func (*KafkaAPIResponse) ProtoMessage()    {}
func (*KafkaAPIResponse) Descriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{5}
}
func (m *KafkaAPIResponse) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_KafkaAPIResponse.Unmarshal(m, b)
}
func (m *KafkaAPIResponse) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_KafkaAPIResponse.Marshal(b, m, deterministic)
}
func (dst *KafkaAPIResponse) XXX_Merge(src proto.Message) {
	xxx_messageInfo_KafkaAPIResponse.Merge(dst, src)
}
func (m *KafkaAPIResponse) XXX_Size() int {
	return xxx_messageInfo_KafkaAPIResponse.Size(m)
}
func (m *KafkaAPIResponse) XXX_DiscardUnknown() {
	xxx_messageInfo_KafkaAPIResponse.DiscardUnknown(m)
}

var xxx_messageInfo_KafkaAPIResponse proto.InternalMessageInfo

// KafkaTopicRequest wraps control-plane operations
// cc-structs reference
// https://github.com/confluentinc/cc-structs/blob/d247737ab9d496cd3c8deab67ba14139871c887c/kafka/scheduler/v1/scheduler.proto#L408-L447
type KafkaTopicRequest struct {
	Cluster              *v1.KafkaCluster `protobuf:"bytes,1,opt,name=cluster" json:"cluster,omitempty"`
	Topic                *Topic           `protobuf:"bytes,2,opt,name=topic" json:"topic,omitempty"`
	XXX_NoUnkeyedLiteral struct{}         `json:"-"`
	XXX_unrecognized     []byte           `json:"-"`
	XXX_sizecache        int32            `json:"-"`
}

func (m *KafkaTopicRequest) Reset()         { *m = KafkaTopicRequest{} }
func (m *KafkaTopicRequest) String() string { return proto.CompactTextString(m) }
func (*KafkaTopicRequest) ProtoMessage()    {}
func (*KafkaTopicRequest) Descriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{6}
}
func (m *KafkaTopicRequest) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_KafkaTopicRequest.Unmarshal(m, b)
}
func (m *KafkaTopicRequest) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_KafkaTopicRequest.Marshal(b, m, deterministic)
}
func (dst *KafkaTopicRequest) XXX_Merge(src proto.Message) {
	xxx_messageInfo_KafkaTopicRequest.Merge(dst, src)
}
func (m *KafkaTopicRequest) XXX_Size() int {
	return xxx_messageInfo_KafkaTopicRequest.Size(m)
}
func (m *KafkaTopicRequest) XXX_DiscardUnknown() {
	xxx_messageInfo_KafkaTopicRequest.DiscardUnknown(m)
}

var xxx_messageInfo_KafkaTopicRequest proto.InternalMessageInfo

func (m *KafkaTopicRequest) GetCluster() *v1.KafkaCluster {
	if m != nil {
		return m.Cluster
	}
	return nil
}

func (m *KafkaTopicRequest) GetTopic() *Topic {
	if m != nil {
		return m.Topic
	}
	return nil
}

// ListTopicParams represents the ListTopic empty param list
type ListTopicParams struct {
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *ListTopicParams) Reset()         { *m = ListTopicParams{} }
func (m *ListTopicParams) String() string { return proto.CompactTextString(m) }
func (*ListTopicParams) ProtoMessage()    {}
func (*ListTopicParams) Descriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{7}
}
func (m *ListTopicParams) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_ListTopicParams.Unmarshal(m, b)
}
func (m *ListTopicParams) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_ListTopicParams.Marshal(b, m, deterministic)
}
func (dst *ListTopicParams) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ListTopicParams.Merge(dst, src)
}
func (m *ListTopicParams) XXX_Size() int {
	return xxx_messageInfo_ListTopicParams.Size(m)
}
func (m *ListTopicParams) XXX_DiscardUnknown() {
	xxx_messageInfo_ListTopicParams.DiscardUnknown(m)
}

var xxx_messageInfo_ListTopicParams proto.InternalMessageInfo

// ListKafkaTopicReply returns an array of topic names
type ListKafkaTopicReply struct {
	Topics               []string `protobuf:"bytes,1,rep,name=topics" json:"topics,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *ListKafkaTopicReply) Reset()         { *m = ListKafkaTopicReply{} }
func (m *ListKafkaTopicReply) String() string { return proto.CompactTextString(m) }
func (*ListKafkaTopicReply) ProtoMessage()    {}
func (*ListKafkaTopicReply) Descriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{8}
}
func (m *ListKafkaTopicReply) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_ListKafkaTopicReply.Unmarshal(m, b)
}
func (m *ListKafkaTopicReply) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_ListKafkaTopicReply.Marshal(b, m, deterministic)
}
func (dst *ListKafkaTopicReply) XXX_Merge(src proto.Message) {
	xxx_messageInfo_ListKafkaTopicReply.Merge(dst, src)
}
func (m *ListKafkaTopicReply) XXX_Size() int {
	return xxx_messageInfo_ListKafkaTopicReply.Size(m)
}
func (m *ListKafkaTopicReply) XXX_DiscardUnknown() {
	xxx_messageInfo_ListKafkaTopicReply.DiscardUnknown(m)
}

var xxx_messageInfo_ListKafkaTopicReply proto.InternalMessageInfo

func (m *ListKafkaTopicReply) GetTopics() []string {
	if m != nil {
		return m.Topics
	}
	return nil
}

// KafkaTopicSpecification wraps NewTopic
// Apache Kafka reference
// https://github.com/confluentinc/cc-kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/admin/NewTopic.java
type KafkaTopicSpecification struct {
	Name                 string            `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	NumPartitions        uint32            `protobuf:"varint,2,opt,name=numPartitions,proto3" json:"numPartitions,omitempty"`
	ReplicationFactor    uint32            `protobuf:"varint,3,opt,name=replicationFactor,proto3" json:"replicationFactor,omitempty"`
	Configs              map[string]string `protobuf:"bytes,5,rep,name=configs" json:"configs,omitempty" protobuf_key:"bytes,1,opt,name=key,proto3" protobuf_val:"bytes,2,opt,name=value,proto3"`
	XXX_NoUnkeyedLiteral struct{}          `json:"-"`
	XXX_unrecognized     []byte            `json:"-"`
	XXX_sizecache        int32             `json:"-"`
}

func (m *KafkaTopicSpecification) Reset()         { *m = KafkaTopicSpecification{} }
func (m *KafkaTopicSpecification) String() string { return proto.CompactTextString(m) }
func (*KafkaTopicSpecification) ProtoMessage()    {}
func (*KafkaTopicSpecification) Descriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{9}
}
func (m *KafkaTopicSpecification) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_KafkaTopicSpecification.Unmarshal(m, b)
}
func (m *KafkaTopicSpecification) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_KafkaTopicSpecification.Marshal(b, m, deterministic)
}
func (dst *KafkaTopicSpecification) XXX_Merge(src proto.Message) {
	xxx_messageInfo_KafkaTopicSpecification.Merge(dst, src)
}
func (m *KafkaTopicSpecification) XXX_Size() int {
	return xxx_messageInfo_KafkaTopicSpecification.Size(m)
}
func (m *KafkaTopicSpecification) XXX_DiscardUnknown() {
	xxx_messageInfo_KafkaTopicSpecification.DiscardUnknown(m)
}

var xxx_messageInfo_KafkaTopicSpecification proto.InternalMessageInfo

func (m *KafkaTopicSpecification) GetName() string {
	if m != nil {
		return m.Name
	}
	return ""
}

func (m *KafkaTopicSpecification) GetNumPartitions() uint32 {
	if m != nil {
		return m.NumPartitions
	}
	return 0
}

func (m *KafkaTopicSpecification) GetReplicationFactor() uint32 {
	if m != nil {
		return m.ReplicationFactor
	}
	return 0
}

func (m *KafkaTopicSpecification) GetConfigs() map[string]string {
	if m != nil {
		return m.Configs
	}
	return nil
}

// Topic describes a Kafka Topic request.
type Topic struct {
	Spec                 *KafkaTopicSpecification `protobuf:"bytes,1,opt,name=spec" json:"spec,omitempty"`
	Validate             bool                     `protobuf:"varint,2,opt,name=validate,proto3" json:"validate,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                 `json:"-"`
	XXX_unrecognized     []byte                   `json:"-"`
	XXX_sizecache        int32                    `json:"-"`
}

func (m *Topic) Reset()         { *m = Topic{} }
func (m *Topic) String() string { return proto.CompactTextString(m) }
func (*Topic) ProtoMessage()    {}
func (*Topic) Descriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{10}
}
func (m *Topic) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_Topic.Unmarshal(m, b)
}
func (m *Topic) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_Topic.Marshal(b, m, deterministic)
}
func (dst *Topic) XXX_Merge(src proto.Message) {
	xxx_messageInfo_Topic.Merge(dst, src)
}
func (m *Topic) XXX_Size() int {
	return xxx_messageInfo_Topic.Size(m)
}
func (m *Topic) XXX_DiscardUnknown() {
	xxx_messageInfo_Topic.DiscardUnknown(m)
}

var xxx_messageInfo_Topic proto.InternalMessageInfo

func (m *Topic) GetSpec() *KafkaTopicSpecification {
	if m != nil {
		return m.Spec
	}
	return nil
}

func (m *Topic) GetValidate() bool {
	if m != nil {
		return m.Validate
	}
	return false
}

// KafkaNode wraps Node
// Apache Kafka reference
// https://github.com/confluentinc/cc-kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/Node.java
type KafkaNode struct {
	Id                   uint32   `protobuf:"varint,1,opt,name=id,proto3" json:"id,omitempty"`
	Port                 uint32   `protobuf:"varint,2,opt,name=port,proto3" json:"port,omitempty"`
	Host                 string   `protobuf:"bytes,3,opt,name=host,proto3" json:"host,omitempty"`
	Rack                 string   `protobuf:"bytes,4,opt,name=rack,proto3" json:"rack,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *KafkaNode) Reset()         { *m = KafkaNode{} }
func (m *KafkaNode) String() string { return proto.CompactTextString(m) }
func (*KafkaNode) ProtoMessage()    {}
func (*KafkaNode) Descriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{11}
}
func (m *KafkaNode) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_KafkaNode.Unmarshal(m, b)
}
func (m *KafkaNode) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_KafkaNode.Marshal(b, m, deterministic)
}
func (dst *KafkaNode) XXX_Merge(src proto.Message) {
	xxx_messageInfo_KafkaNode.Merge(dst, src)
}
func (m *KafkaNode) XXX_Size() int {
	return xxx_messageInfo_KafkaNode.Size(m)
}
func (m *KafkaNode) XXX_DiscardUnknown() {
	xxx_messageInfo_KafkaNode.DiscardUnknown(m)
}

var xxx_messageInfo_KafkaNode proto.InternalMessageInfo

func (m *KafkaNode) GetId() uint32 {
	if m != nil {
		return m.Id
	}
	return 0
}

func (m *KafkaNode) GetPort() uint32 {
	if m != nil {
		return m.Port
	}
	return 0
}

func (m *KafkaNode) GetHost() string {
	if m != nil {
		return m.Host
	}
	return ""
}

func (m *KafkaNode) GetRack() string {
	if m != nil {
		return m.Rack
	}
	return ""
}

// KafkaTopicPartitionInfo wraps TopicPartitionInfo
// Apache Kafka reference
// https://github.com/confluentinc/cc-kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/TopicPartitionInfo.java
type KafkaTopicPartitionInfo struct {
	Partition            uint32       `protobuf:"varint,1,opt,name=Partition,proto3" json:"Partition,omitempty"`
	Leader               *KafkaNode   `protobuf:"bytes,2,opt,name=Leader" json:"Leader,omitempty"`
	Replicas             []*KafkaNode `protobuf:"bytes,3,rep,name=Replicas" json:"Replicas,omitempty"`
	ISR                  []*KafkaNode `protobuf:"bytes,4,rep,name=ISR" json:"ISR,omitempty"`
	XXX_NoUnkeyedLiteral struct{}     `json:"-"`
	XXX_unrecognized     []byte       `json:"-"`
	XXX_sizecache        int32        `json:"-"`
}

func (m *KafkaTopicPartitionInfo) Reset()         { *m = KafkaTopicPartitionInfo{} }
func (m *KafkaTopicPartitionInfo) String() string { return proto.CompactTextString(m) }
func (*KafkaTopicPartitionInfo) ProtoMessage()    {}
func (*KafkaTopicPartitionInfo) Descriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{12}
}
func (m *KafkaTopicPartitionInfo) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_KafkaTopicPartitionInfo.Unmarshal(m, b)
}
func (m *KafkaTopicPartitionInfo) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_KafkaTopicPartitionInfo.Marshal(b, m, deterministic)
}
func (dst *KafkaTopicPartitionInfo) XXX_Merge(src proto.Message) {
	xxx_messageInfo_KafkaTopicPartitionInfo.Merge(dst, src)
}
func (m *KafkaTopicPartitionInfo) XXX_Size() int {
	return xxx_messageInfo_KafkaTopicPartitionInfo.Size(m)
}
func (m *KafkaTopicPartitionInfo) XXX_DiscardUnknown() {
	xxx_messageInfo_KafkaTopicPartitionInfo.DiscardUnknown(m)
}

var xxx_messageInfo_KafkaTopicPartitionInfo proto.InternalMessageInfo

func (m *KafkaTopicPartitionInfo) GetPartition() uint32 {
	if m != nil {
		return m.Partition
	}
	return 0
}

func (m *KafkaTopicPartitionInfo) GetLeader() *KafkaNode {
	if m != nil {
		return m.Leader
	}
	return nil
}

func (m *KafkaTopicPartitionInfo) GetReplicas() []*KafkaNode {
	if m != nil {
		return m.Replicas
	}
	return nil
}

func (m *KafkaTopicPartitionInfo) GetISR() []*KafkaNode {
	if m != nil {
		return m.ISR
	}
	return nil
}

// KafkaATopicDescription wraps TopicDescription
// Apache Kafka reference
// https://github.com/confluentinc/cc-kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/admin/TopicDescription.java
type KafkaTopicDescription struct {
	Name                 string                     `protobuf:"bytes,1,opt,name=Name,proto3" json:"Name,omitempty"`
	Internal             bool                       `protobuf:"varint,2,opt,name=Internal,proto3" json:"Internal,omitempty"`
	Config               []*KafkaTopicConfigEntry   `protobuf:"bytes,3,rep,name=config" json:"config,omitempty"`
	Partitions           []*KafkaTopicPartitionInfo `protobuf:"bytes,4,rep,name=Partitions" json:"Partitions,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                   `json:"-"`
	XXX_unrecognized     []byte                     `json:"-"`
	XXX_sizecache        int32                      `json:"-"`
}

func (m *KafkaTopicDescription) Reset()         { *m = KafkaTopicDescription{} }
func (m *KafkaTopicDescription) String() string { return proto.CompactTextString(m) }
func (*KafkaTopicDescription) ProtoMessage()    {}
func (*KafkaTopicDescription) Descriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{13}
}
func (m *KafkaTopicDescription) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_KafkaTopicDescription.Unmarshal(m, b)
}
func (m *KafkaTopicDescription) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_KafkaTopicDescription.Marshal(b, m, deterministic)
}
func (dst *KafkaTopicDescription) XXX_Merge(src proto.Message) {
	xxx_messageInfo_KafkaTopicDescription.Merge(dst, src)
}
func (m *KafkaTopicDescription) XXX_Size() int {
	return xxx_messageInfo_KafkaTopicDescription.Size(m)
}
func (m *KafkaTopicDescription) XXX_DiscardUnknown() {
	xxx_messageInfo_KafkaTopicDescription.DiscardUnknown(m)
}

var xxx_messageInfo_KafkaTopicDescription proto.InternalMessageInfo

func (m *KafkaTopicDescription) GetName() string {
	if m != nil {
		return m.Name
	}
	return ""
}

func (m *KafkaTopicDescription) GetInternal() bool {
	if m != nil {
		return m.Internal
	}
	return false
}

func (m *KafkaTopicDescription) GetConfig() []*KafkaTopicConfigEntry {
	if m != nil {
		return m.Config
	}
	return nil
}

func (m *KafkaTopicDescription) GetPartitions() []*KafkaTopicPartitionInfo {
	if m != nil {
		return m.Partitions
	}
	return nil
}

// KafkaTopicConfigSynonym describes alternative names(topic-level overides) for Kafka Configuration Entries
// Apache Kafka reference
// https://github.com/confluentinc/cc-kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/admin/ConfigEntry.java
type KafkaTopicConfigSynonym struct {
	Name                 string   `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	Value                string   `protobuf:"bytes,2,opt,name=value,proto3" json:"value,omitempty"`
	Source               string   `protobuf:"bytes,3,opt,name=source,proto3" json:"source,omitempty"`
	XXX_NoUnkeyedLiteral struct{} `json:"-"`
	XXX_unrecognized     []byte   `json:"-"`
	XXX_sizecache        int32    `json:"-"`
}

func (m *KafkaTopicConfigSynonym) Reset()         { *m = KafkaTopicConfigSynonym{} }
func (m *KafkaTopicConfigSynonym) String() string { return proto.CompactTextString(m) }
func (*KafkaTopicConfigSynonym) ProtoMessage()    {}
func (*KafkaTopicConfigSynonym) Descriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{14}
}
func (m *KafkaTopicConfigSynonym) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_KafkaTopicConfigSynonym.Unmarshal(m, b)
}
func (m *KafkaTopicConfigSynonym) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_KafkaTopicConfigSynonym.Marshal(b, m, deterministic)
}
func (dst *KafkaTopicConfigSynonym) XXX_Merge(src proto.Message) {
	xxx_messageInfo_KafkaTopicConfigSynonym.Merge(dst, src)
}
func (m *KafkaTopicConfigSynonym) XXX_Size() int {
	return xxx_messageInfo_KafkaTopicConfigSynonym.Size(m)
}
func (m *KafkaTopicConfigSynonym) XXX_DiscardUnknown() {
	xxx_messageInfo_KafkaTopicConfigSynonym.DiscardUnknown(m)
}

var xxx_messageInfo_KafkaTopicConfigSynonym proto.InternalMessageInfo

func (m *KafkaTopicConfigSynonym) GetName() string {
	if m != nil {
		return m.Name
	}
	return ""
}

func (m *KafkaTopicConfigSynonym) GetValue() string {
	if m != nil {
		return m.Value
	}
	return ""
}

func (m *KafkaTopicConfigSynonym) GetSource() string {
	if m != nil {
		return m.Source
	}
	return ""
}

// KafkaTopicConfigEntry describes a Configuration Entry
// Apache Kafka reference
// https://github.com/confluentinc/cc-kafka/blob/trunk/clients/src/main/java/org/apache/kafka/clients/admin/ConfigEntry.java
type KafkaTopicConfigEntry struct {
	Name                 string                     `protobuf:"bytes,1,opt,name=name,proto3" json:"name,omitempty"`
	Value                string                     `protobuf:"bytes,2,opt,name=value,proto3" json:"value,omitempty"`
	Source               string                     `protobuf:"bytes,3,opt,name=source,proto3" json:"source,omitempty"`
	Synonyms             []*KafkaTopicConfigSynonym `protobuf:"bytes,4,rep,name=synonyms" json:"synonyms,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                   `json:"-"`
	XXX_unrecognized     []byte                     `json:"-"`
	XXX_sizecache        int32                      `json:"-"`
}

func (m *KafkaTopicConfigEntry) Reset()         { *m = KafkaTopicConfigEntry{} }
func (m *KafkaTopicConfigEntry) String() string { return proto.CompactTextString(m) }
func (*KafkaTopicConfigEntry) ProtoMessage()    {}
func (*KafkaTopicConfigEntry) Descriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{15}
}
func (m *KafkaTopicConfigEntry) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_KafkaTopicConfigEntry.Unmarshal(m, b)
}
func (m *KafkaTopicConfigEntry) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_KafkaTopicConfigEntry.Marshal(b, m, deterministic)
}
func (dst *KafkaTopicConfigEntry) XXX_Merge(src proto.Message) {
	xxx_messageInfo_KafkaTopicConfigEntry.Merge(dst, src)
}
func (m *KafkaTopicConfigEntry) XXX_Size() int {
	return xxx_messageInfo_KafkaTopicConfigEntry.Size(m)
}
func (m *KafkaTopicConfigEntry) XXX_DiscardUnknown() {
	xxx_messageInfo_KafkaTopicConfigEntry.DiscardUnknown(m)
}

var xxx_messageInfo_KafkaTopicConfigEntry proto.InternalMessageInfo

func (m *KafkaTopicConfigEntry) GetName() string {
	if m != nil {
		return m.Name
	}
	return ""
}

func (m *KafkaTopicConfigEntry) GetValue() string {
	if m != nil {
		return m.Value
	}
	return ""
}

func (m *KafkaTopicConfigEntry) GetSource() string {
	if m != nil {
		return m.Source
	}
	return ""
}

func (m *KafkaTopicConfigEntry) GetSynonyms() []*KafkaTopicConfigSynonym {
	if m != nil {
		return m.Synonyms
	}
	return nil
}

// KafkaConfigRequest describes a collection of KafkaConfigEntry
type TopicConfig struct {
	Entries              []*KafkaTopicConfigEntry `protobuf:"bytes,1,rep,name=entries" json:"entries,omitempty"`
	XXX_NoUnkeyedLiteral struct{}                 `json:"-"`
	XXX_unrecognized     []byte                   `json:"-"`
	XXX_sizecache        int32                    `json:"-"`
}

func (m *TopicConfig) Reset()         { *m = TopicConfig{} }
func (m *TopicConfig) String() string { return proto.CompactTextString(m) }
func (*TopicConfig) ProtoMessage()    {}
func (*TopicConfig) Descriptor() ([]byte, []int) {
	return fileDescriptor_kafka_3de71f486cda0ca4, []int{16}
}
func (m *TopicConfig) XXX_Unmarshal(b []byte) error {
	return xxx_messageInfo_TopicConfig.Unmarshal(m, b)
}
func (m *TopicConfig) XXX_Marshal(b []byte, deterministic bool) ([]byte, error) {
	return xxx_messageInfo_TopicConfig.Marshal(b, m, deterministic)
}
func (dst *TopicConfig) XXX_Merge(src proto.Message) {
	xxx_messageInfo_TopicConfig.Merge(dst, src)
}
func (m *TopicConfig) XXX_Size() int {
	return xxx_messageInfo_TopicConfig.Size(m)
}
func (m *TopicConfig) XXX_DiscardUnknown() {
	xxx_messageInfo_TopicConfig.DiscardUnknown(m)
}

var xxx_messageInfo_TopicConfig proto.InternalMessageInfo

func (m *TopicConfig) GetEntries() []*KafkaTopicConfigEntry {
	if m != nil {
		return m.Entries
	}
	return nil
}

func init() {
	proto.RegisterType((*AccessControlEntryConfig)(nil), "kafka.AccessControlEntryConfig")
	proto.RegisterType((*ResourcePatternConfig)(nil), "kafka.ResourcePatternConfig")
	proto.RegisterType((*ACLSpec)(nil), "kafka.ACLSpec")
	proto.RegisterType((*ACLFilter)(nil), "kafka.ACLFilter")
	proto.RegisterType((*KafkaAPIACLFilterReply)(nil), "kafka.KafkaAPIACLFilterReply")
	proto.RegisterType((*KafkaAPIResponse)(nil), "kafka.KafkaAPIResponse")
	proto.RegisterType((*KafkaTopicRequest)(nil), "kafka.KafkaTopicRequest")
	proto.RegisterType((*ListTopicParams)(nil), "kafka.ListTopicParams")
	proto.RegisterType((*ListKafkaTopicReply)(nil), "kafka.ListKafkaTopicReply")
	proto.RegisterType((*KafkaTopicSpecification)(nil), "kafka.KafkaTopicSpecification")
	proto.RegisterMapType((map[string]string)(nil), "kafka.KafkaTopicSpecification.ConfigsEntry")
	proto.RegisterType((*Topic)(nil), "kafka.Topic")
	proto.RegisterType((*KafkaNode)(nil), "kafka.KafkaNode")
	proto.RegisterType((*KafkaTopicPartitionInfo)(nil), "kafka.KafkaTopicPartitionInfo")
	proto.RegisterType((*KafkaTopicDescription)(nil), "kafka.KafkaTopicDescription")
	proto.RegisterType((*KafkaTopicConfigSynonym)(nil), "kafka.KafkaTopicConfigSynonym")
	proto.RegisterType((*KafkaTopicConfigEntry)(nil), "kafka.KafkaTopicConfigEntry")
	proto.RegisterType((*TopicConfig)(nil), "kafka.TopicConfig")
	proto.RegisterEnum("kafka.KafkaTopicConfigSource", KafkaTopicConfigSource_name, KafkaTopicConfigSource_value)
	proto.RegisterEnum("kafka.AccessControlEntryConfig_FilterType", AccessControlEntryConfig_FilterType_name, AccessControlEntryConfig_FilterType_value)
	proto.RegisterEnum("kafka.AccessControlEntryConfig_ACLPermissionType", AccessControlEntryConfig_ACLPermissionType_name, AccessControlEntryConfig_ACLPermissionType_value)
	proto.RegisterEnum("kafka.AccessControlEntryConfig_ACLOperation", AccessControlEntryConfig_ACLOperation_name, AccessControlEntryConfig_ACLOperation_value)
	proto.RegisterEnum("kafka.ResourcePatternConfig_FilterType", ResourcePatternConfig_FilterType_name, ResourcePatternConfig_FilterType_value)
	proto.RegisterEnum("kafka.ResourcePatternConfig_ResourceType", ResourcePatternConfig_ResourceType_name, ResourcePatternConfig_ResourceType_value)
	proto.RegisterEnum("kafka.ResourcePatternConfig_PatternType", ResourcePatternConfig_PatternType_name, ResourcePatternConfig_PatternType_value)
}

// Reference imports to suppress errors if they are not otherwise used.
var _ context.Context
var _ grpc.ClientConn

// This is a compile-time assertion to ensure that this generated file
// is compatible with the grpc package it is being compiled against.
const _ = grpc.SupportPackageIsVersion4

// KafkaClient is the client API for Kafka service.
//
// For semantics around ctx use and closing/ending streaming RPCs, please refer to https://godoc.org/google.golang.org/grpc#ClientConn.NewStream.
type KafkaClient interface {
	CreateAPIKey(ctx context.Context, in *v1.CreateApiKeyRequest, opts ...grpc.CallOption) (*v1.CreateApiKeyReply, error)
	List(ctx context.Context, in *v1.GetKafkaClustersRequest, opts ...grpc.CallOption) (*v1.GetKafkaClustersReply, error)
	Describe(ctx context.Context, in *v1.GetKafkaClusterRequest, opts ...grpc.CallOption) (*v1.GetKafkaClusterReply, error)
	Create(ctx context.Context, in *v1.CreateKafkaClusterRequest, opts ...grpc.CallOption) (*v1.CreateKafkaClusterReply, error)
	Delete(ctx context.Context, in *v1.DeleteKafkaClusterRequest, opts ...grpc.CallOption) (*v1.DeleteKafkaClusterReply, error)
	ListTopics(ctx context.Context, in *KafkaTopicRequest, opts ...grpc.CallOption) (*ListKafkaTopicReply, error)
	DescribeTopic(ctx context.Context, in *KafkaTopicRequest, opts ...grpc.CallOption) (*KafkaTopicDescription, error)
	CreateTopic(ctx context.Context, in *KafkaTopicRequest, opts ...grpc.CallOption) (*KafkaAPIResponse, error)
	DeleteTopic(ctx context.Context, in *KafkaTopicRequest, opts ...grpc.CallOption) (*KafkaAPIResponse, error)
	UpdateTopic(ctx context.Context, in *KafkaTopicRequest, opts ...grpc.CallOption) (*KafkaAPIResponse, error)
	ListACL(ctx context.Context, in *ACLFilter, opts ...grpc.CallOption) (*KafkaAPIACLFilterReply, error)
	CreateACL(ctx context.Context, in *ACLSpec, opts ...grpc.CallOption) (*KafkaAPIResponse, error)
	DeleteACL(ctx context.Context, in *ACLFilter, opts ...grpc.CallOption) (*KafkaAPIResponse, error)
}

type kafkaClient struct {
	cc *grpc.ClientConn
}

func NewKafkaClient(cc *grpc.ClientConn) KafkaClient {
	return &kafkaClient{cc}
}

func (c *kafkaClient) CreateAPIKey(ctx context.Context, in *v1.CreateApiKeyRequest, opts ...grpc.CallOption) (*v1.CreateApiKeyReply, error) {
	out := new(v1.CreateApiKeyReply)
	err := c.cc.Invoke(ctx, "/kafka.Kafka/CreateAPIKey", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kafkaClient) List(ctx context.Context, in *v1.GetKafkaClustersRequest, opts ...grpc.CallOption) (*v1.GetKafkaClustersReply, error) {
	out := new(v1.GetKafkaClustersReply)
	err := c.cc.Invoke(ctx, "/kafka.Kafka/List", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kafkaClient) Describe(ctx context.Context, in *v1.GetKafkaClusterRequest, opts ...grpc.CallOption) (*v1.GetKafkaClusterReply, error) {
	out := new(v1.GetKafkaClusterReply)
	err := c.cc.Invoke(ctx, "/kafka.Kafka/Describe", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kafkaClient) Create(ctx context.Context, in *v1.CreateKafkaClusterRequest, opts ...grpc.CallOption) (*v1.CreateKafkaClusterReply, error) {
	out := new(v1.CreateKafkaClusterReply)
	err := c.cc.Invoke(ctx, "/kafka.Kafka/Create", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kafkaClient) Delete(ctx context.Context, in *v1.DeleteKafkaClusterRequest, opts ...grpc.CallOption) (*v1.DeleteKafkaClusterReply, error) {
	out := new(v1.DeleteKafkaClusterReply)
	err := c.cc.Invoke(ctx, "/kafka.Kafka/Delete", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kafkaClient) ListTopics(ctx context.Context, in *KafkaTopicRequest, opts ...grpc.CallOption) (*ListKafkaTopicReply, error) {
	out := new(ListKafkaTopicReply)
	err := c.cc.Invoke(ctx, "/kafka.Kafka/ListTopics", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kafkaClient) DescribeTopic(ctx context.Context, in *KafkaTopicRequest, opts ...grpc.CallOption) (*KafkaTopicDescription, error) {
	out := new(KafkaTopicDescription)
	err := c.cc.Invoke(ctx, "/kafka.Kafka/DescribeTopic", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kafkaClient) CreateTopic(ctx context.Context, in *KafkaTopicRequest, opts ...grpc.CallOption) (*KafkaAPIResponse, error) {
	out := new(KafkaAPIResponse)
	err := c.cc.Invoke(ctx, "/kafka.Kafka/CreateTopic", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kafkaClient) DeleteTopic(ctx context.Context, in *KafkaTopicRequest, opts ...grpc.CallOption) (*KafkaAPIResponse, error) {
	out := new(KafkaAPIResponse)
	err := c.cc.Invoke(ctx, "/kafka.Kafka/DeleteTopic", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kafkaClient) UpdateTopic(ctx context.Context, in *KafkaTopicRequest, opts ...grpc.CallOption) (*KafkaAPIResponse, error) {
	out := new(KafkaAPIResponse)
	err := c.cc.Invoke(ctx, "/kafka.Kafka/UpdateTopic", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kafkaClient) ListACL(ctx context.Context, in *ACLFilter, opts ...grpc.CallOption) (*KafkaAPIACLFilterReply, error) {
	out := new(KafkaAPIACLFilterReply)
	err := c.cc.Invoke(ctx, "/kafka.Kafka/ListACL", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kafkaClient) CreateACL(ctx context.Context, in *ACLSpec, opts ...grpc.CallOption) (*KafkaAPIResponse, error) {
	out := new(KafkaAPIResponse)
	err := c.cc.Invoke(ctx, "/kafka.Kafka/CreateACL", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

func (c *kafkaClient) DeleteACL(ctx context.Context, in *ACLFilter, opts ...grpc.CallOption) (*KafkaAPIResponse, error) {
	out := new(KafkaAPIResponse)
	err := c.cc.Invoke(ctx, "/kafka.Kafka/DeleteACL", in, out, opts...)
	if err != nil {
		return nil, err
	}
	return out, nil
}

// KafkaServer is the server API for Kafka service.
type KafkaServer interface {
	CreateAPIKey(context.Context, *v1.CreateApiKeyRequest) (*v1.CreateApiKeyReply, error)
	List(context.Context, *v1.GetKafkaClustersRequest) (*v1.GetKafkaClustersReply, error)
	Describe(context.Context, *v1.GetKafkaClusterRequest) (*v1.GetKafkaClusterReply, error)
	Create(context.Context, *v1.CreateKafkaClusterRequest) (*v1.CreateKafkaClusterReply, error)
	Delete(context.Context, *v1.DeleteKafkaClusterRequest) (*v1.DeleteKafkaClusterReply, error)
	ListTopics(context.Context, *KafkaTopicRequest) (*ListKafkaTopicReply, error)
	DescribeTopic(context.Context, *KafkaTopicRequest) (*KafkaTopicDescription, error)
	CreateTopic(context.Context, *KafkaTopicRequest) (*KafkaAPIResponse, error)
	DeleteTopic(context.Context, *KafkaTopicRequest) (*KafkaAPIResponse, error)
	UpdateTopic(context.Context, *KafkaTopicRequest) (*KafkaAPIResponse, error)
	ListACL(context.Context, *ACLFilter) (*KafkaAPIACLFilterReply, error)
	CreateACL(context.Context, *ACLSpec) (*KafkaAPIResponse, error)
	DeleteACL(context.Context, *ACLFilter) (*KafkaAPIResponse, error)
}

func RegisterKafkaServer(s *grpc.Server, srv KafkaServer) {
	s.RegisterService(&_Kafka_serviceDesc, srv)
}

func _Kafka_CreateAPIKey_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(v1.CreateApiKeyRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaServer).CreateAPIKey(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/kafka.Kafka/CreateAPIKey",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaServer).CreateAPIKey(ctx, req.(*v1.CreateApiKeyRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _Kafka_List_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(v1.GetKafkaClustersRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaServer).List(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/kafka.Kafka/List",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaServer).List(ctx, req.(*v1.GetKafkaClustersRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _Kafka_Describe_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(v1.GetKafkaClusterRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaServer).Describe(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/kafka.Kafka/Describe",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaServer).Describe(ctx, req.(*v1.GetKafkaClusterRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _Kafka_Create_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(v1.CreateKafkaClusterRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaServer).Create(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/kafka.Kafka/Create",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaServer).Create(ctx, req.(*v1.CreateKafkaClusterRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _Kafka_Delete_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(v1.DeleteKafkaClusterRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaServer).Delete(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/kafka.Kafka/Delete",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaServer).Delete(ctx, req.(*v1.DeleteKafkaClusterRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _Kafka_ListTopics_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(KafkaTopicRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaServer).ListTopics(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/kafka.Kafka/ListTopics",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaServer).ListTopics(ctx, req.(*KafkaTopicRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _Kafka_DescribeTopic_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(KafkaTopicRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaServer).DescribeTopic(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/kafka.Kafka/DescribeTopic",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaServer).DescribeTopic(ctx, req.(*KafkaTopicRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _Kafka_CreateTopic_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(KafkaTopicRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaServer).CreateTopic(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/kafka.Kafka/CreateTopic",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaServer).CreateTopic(ctx, req.(*KafkaTopicRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _Kafka_DeleteTopic_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(KafkaTopicRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaServer).DeleteTopic(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/kafka.Kafka/DeleteTopic",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaServer).DeleteTopic(ctx, req.(*KafkaTopicRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _Kafka_UpdateTopic_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(KafkaTopicRequest)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaServer).UpdateTopic(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/kafka.Kafka/UpdateTopic",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaServer).UpdateTopic(ctx, req.(*KafkaTopicRequest))
	}
	return interceptor(ctx, in, info, handler)
}

func _Kafka_ListACL_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ACLFilter)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaServer).ListACL(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/kafka.Kafka/ListACL",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaServer).ListACL(ctx, req.(*ACLFilter))
	}
	return interceptor(ctx, in, info, handler)
}

func _Kafka_CreateACL_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ACLSpec)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaServer).CreateACL(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/kafka.Kafka/CreateACL",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaServer).CreateACL(ctx, req.(*ACLSpec))
	}
	return interceptor(ctx, in, info, handler)
}

func _Kafka_DeleteACL_Handler(srv interface{}, ctx context.Context, dec func(interface{}) error, interceptor grpc.UnaryServerInterceptor) (interface{}, error) {
	in := new(ACLFilter)
	if err := dec(in); err != nil {
		return nil, err
	}
	if interceptor == nil {
		return srv.(KafkaServer).DeleteACL(ctx, in)
	}
	info := &grpc.UnaryServerInfo{
		Server:     srv,
		FullMethod: "/kafka.Kafka/DeleteACL",
	}
	handler := func(ctx context.Context, req interface{}) (interface{}, error) {
		return srv.(KafkaServer).DeleteACL(ctx, req.(*ACLFilter))
	}
	return interceptor(ctx, in, info, handler)
}

var _Kafka_serviceDesc = grpc.ServiceDesc{
	ServiceName: "kafka.Kafka",
	HandlerType: (*KafkaServer)(nil),
	Methods: []grpc.MethodDesc{
		{
			MethodName: "CreateAPIKey",
			Handler:    _Kafka_CreateAPIKey_Handler,
		},
		{
			MethodName: "List",
			Handler:    _Kafka_List_Handler,
		},
		{
			MethodName: "Describe",
			Handler:    _Kafka_Describe_Handler,
		},
		{
			MethodName: "Create",
			Handler:    _Kafka_Create_Handler,
		},
		{
			MethodName: "Delete",
			Handler:    _Kafka_Delete_Handler,
		},
		{
			MethodName: "ListTopics",
			Handler:    _Kafka_ListTopics_Handler,
		},
		{
			MethodName: "DescribeTopic",
			Handler:    _Kafka_DescribeTopic_Handler,
		},
		{
			MethodName: "CreateTopic",
			Handler:    _Kafka_CreateTopic_Handler,
		},
		{
			MethodName: "DeleteTopic",
			Handler:    _Kafka_DeleteTopic_Handler,
		},
		{
			MethodName: "UpdateTopic",
			Handler:    _Kafka_UpdateTopic_Handler,
		},
		{
			MethodName: "ListACL",
			Handler:    _Kafka_ListACL_Handler,
		},
		{
			MethodName: "CreateACL",
			Handler:    _Kafka_CreateACL_Handler,
		},
		{
			MethodName: "DeleteACL",
			Handler:    _Kafka_DeleteACL_Handler,
		},
	},
	Streams:  []grpc.StreamDesc{},
	Metadata: "kafka.proto",
}

func init() { proto.RegisterFile("kafka.proto", fileDescriptor_kafka_3de71f486cda0ca4) }

var fileDescriptor_kafka_3de71f486cda0ca4 = []byte{
	// 1343 bytes of a gzipped FileDescriptorProto
	0x1f, 0x8b, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xff, 0xa4, 0x57, 0x4b, 0x6f, 0xdb, 0xc6,
	0x16, 0x16, 0xf5, 0xd6, 0x91, 0xe4, 0x4b, 0xcf, 0x8d, 0x13, 0x5d, 0x23, 0xb9, 0xd7, 0x77, 0xd0,
	0x87, 0x9a, 0x87, 0x83, 0xb8, 0x6d, 0x10, 0x18, 0x45, 0x01, 0x9a, 0xa2, 0x5d, 0xc2, 0x8c, 0x24,
	0x8c, 0x68, 0xb8, 0x41, 0x17, 0x0e, 0x43, 0x8d, 0x1b, 0xc2, 0x32, 0xc9, 0x92, 0x94, 0x51, 0xed,
	0x8b, 0xac, 0xba, 0x2a, 0xd0, 0x5f, 0xd1, 0x4d, 0x81, 0xae, 0xfb, 0xdf, 0x8a, 0x79, 0x90, 0xa2,
	0x2c, 0x29, 0x11, 0x90, 0x95, 0x66, 0xce, 0xf9, 0xce, 0x77, 0x5e, 0x33, 0x67, 0x28, 0x68, 0x5e,
	0x39, 0x97, 0x57, 0xce, 0x7e, 0x18, 0x05, 0x49, 0x80, 0x2a, 0x7c, 0xb3, 0x8b, 0xf9, 0xcf, 0xd3,
	0xd8, 0x7d, 0x4b, 0xc7, 0xd3, 0x09, 0x8d, 0x9e, 0xde, 0x3c, 0x9b, 0x6f, 0x04, 0x14, 0xbf, 0x2b,
	0x41, 0x47, 0x73, 0x5d, 0x1a, 0xc7, 0x7a, 0xe0, 0x27, 0x51, 0x30, 0x31, 0xfc, 0x24, 0x9a, 0xe9,
	0x81, 0x7f, 0xe9, 0xfd, 0x88, 0xee, 0x43, 0x23, 0x8c, 0x3c, 0xdf, 0xf5, 0x42, 0x67, 0xd2, 0x51,
	0xf6, 0x94, 0x6e, 0x83, 0xcc, 0x05, 0x4c, 0x1b, 0x84, 0x34, 0x72, 0x12, 0x2f, 0xf0, 0x3b, 0x45,
	0xa1, 0xcd, 0x04, 0x08, 0x41, 0xf9, 0x6d, 0x10, 0x27, 0x9d, 0x12, 0x57, 0xf0, 0x35, 0xfa, 0x0c,
	0xb6, 0x42, 0x1a, 0x5d, 0x7b, 0x71, 0xec, 0x05, 0xbe, 0x3d, 0x0b, 0x69, 0xa7, 0xcc, 0xb5, 0xb7,
	0xa4, 0x78, 0x07, 0xe0, 0xd8, 0x9b, 0x24, 0x34, 0x62, 0x3b, 0x54, 0x83, 0x92, 0xd6, 0x7f, 0xa5,
	0x16, 0x70, 0x17, 0xb6, 0x35, 0xdd, 0x1a, 0x2e, 0x60, 0x51, 0x03, 0x2a, 0x9a, 0x65, 0x0d, 0xce,
	0xd5, 0x02, 0xaa, 0x43, 0xb9, 0x67, 0xf4, 0x5f, 0xa9, 0x0a, 0xfe, 0x53, 0x81, 0x96, 0xa6, 0x5b,
	0x83, 0x2c, 0x1a, 0xc6, 0x61, 0x59, 0x02, 0x43, 0x0c, 0xad, 0xa7, 0x2a, 0xcc, 0xf0, 0x9c, 0x98,
	0xb6, 0xa1, 0x16, 0x11, 0x40, 0x55, 0x27, 0x86, 0x66, 0x1b, 0x6a, 0x89, 0xad, 0x7b, 0x86, 0x65,
	0xd8, 0x86, 0x5a, 0x16, 0xdc, 0xb6, 0x41, 0xd4, 0x0a, 0x6a, 0x41, 0xbd, 0x67, 0x8c, 0x74, 0x62,
	0x1e, 0x19, 0x6a, 0x15, 0x21, 0xd8, 0xd2, 0xad, 0xb3, 0x91, 0x6d, 0x90, 0x0b, 0x4d, 0xb7, 0xcd,
	0x41, 0x5f, 0xad, 0xa1, 0x3b, 0xa0, 0xa6, 0x88, 0x0b, 0x7d, 0xd0, 0x3f, 0x36, 0x4f, 0x46, 0x6a,
	0x1d, 0x6d, 0x43, 0x9b, 0x53, 0x64, 0xa2, 0x06, 0x03, 0x9a, 0x3d, 0xe3, 0xe5, 0x70, 0x60, 0x1b,
	0x7d, 0xfb, 0x42, 0xc4, 0x00, 0xf8, 0x5d, 0x11, 0x76, 0x08, 0x8d, 0x83, 0x69, 0xe4, 0xd2, 0xa1,
	0x93, 0x24, 0x34, 0xf2, 0x65, 0x17, 0x30, 0xb4, 0x22, 0xa9, 0xe0, 0x35, 0x13, 0x8d, 0x58, 0x90,
	0xb1, 0x6a, 0xfb, 0xce, 0x35, 0x95, 0x6d, 0xe0, 0x6b, 0xb4, 0x07, 0xcd, 0x50, 0x10, 0x71, 0x33,
	0xd1, 0x88, 0xbc, 0x08, 0xef, 0xad, 0xac, 0x33, 0x4b, 0xfb, 0xa5, 0x66, 0xeb, 0xdf, 0xa9, 0x0a,
	0x3e, 0x81, 0x16, 0xc9, 0xfb, 0x69, 0x40, 0xc5, 0x1e, 0x0c, 0x4d, 0x5d, 0xa0, 0x4e, 0xc8, 0xe0,
	0x6c, 0xa8, 0x2a, 0xa8, 0x09, 0x35, 0x59, 0x0e, 0xb5, 0xc8, 0xd2, 0xb3, 0x89, 0xd6, 0x1f, 0x89,
	0xc2, 0x68, 0xd6, 0x85, 0xd9, 0x53, 0x4b, 0xb8, 0x0b, 0xcd, 0xe1, 0xdc, 0x33, 0xb3, 0xb0, 0x4c,
	0xdb, 0x20, 0x1a, 0xeb, 0x49, 0x0b, 0xea, 0x43, 0x62, 0x1c, 0x9b, 0xdf, 0x1b, 0x3d, 0x55, 0xc1,
	0x3f, 0x43, 0x4d, 0xd3, 0xad, 0x51, 0x48, 0x5d, 0xf4, 0x1c, 0x6a, 0x32, 0x5c, 0x9e, 0x74, 0xf3,
	0xe0, 0xfe, 0xbe, 0x38, 0xe6, 0x2b, 0x0b, 0x45, 0x52, 0x30, 0xfa, 0x1a, 0x2a, 0x94, 0x1d, 0x63,
	0x5e, 0x8e, 0xe6, 0xc1, 0xff, 0xa4, 0xd5, 0xba, 0x73, 0x4e, 0x04, 0x1a, 0xff, 0xa6, 0x40, 0x43,
	0xd3, 0x2d, 0x51, 0x12, 0x74, 0x04, 0x6d, 0xc9, 0x27, 0x04, 0x1b, 0x85, 0xb0, 0x68, 0x82, 0x34,
	0x68, 0x72, 0x6a, 0xc9, 0xb0, 0x61, 0x38, 0x79, 0x1b, 0x7c, 0x04, 0x77, 0x4f, 0x19, 0x5c, 0x1b,
	0x9a, 0x59, 0x6c, 0x84, 0x86, 0x93, 0x19, 0xea, 0x42, 0x2d, 0xa2, 0xf1, 0x74, 0x92, 0xc4, 0x1d,
	0x65, 0xaf, 0xd4, 0x6d, 0x1e, 0x6c, 0xa5, 0xc4, 0xa2, 0x7c, 0x24, 0x55, 0x63, 0x04, 0x6a, 0xca,
	0x41, 0x68, 0x1c, 0x06, 0x7e, 0x4c, 0x71, 0x0c, 0xdb, 0x5c, 0x66, 0x07, 0xa1, 0xe7, 0x12, 0xfa,
	0xd3, 0x94, 0xc6, 0x09, 0x3a, 0x84, 0x9a, 0x3b, 0x99, 0xc6, 0xf3, 0x6c, 0xf7, 0x24, 0xe5, 0x7c,
	0x6c, 0xdc, 0x3c, 0xdb, 0xe7, 0x76, 0xba, 0xc0, 0x91, 0xd4, 0x00, 0x61, 0xa8, 0x24, 0x8c, 0x4b,
	0x66, 0xd9, 0x92, 0x96, 0x82, 0x5f, 0xa8, 0xf0, 0x36, 0xfc, 0xcb, 0xf2, 0xe2, 0x84, 0xcb, 0x86,
	0x4e, 0xe4, 0x5c, 0xc7, 0xf8, 0x09, 0xfc, 0x9b, 0x89, 0xf2, 0xb1, 0xb0, 0xe4, 0xee, 0x42, 0x95,
	0x9b, 0x88, 0xdc, 0x1a, 0x44, 0xee, 0xf0, 0x2f, 0x45, 0xb8, 0x37, 0xc7, 0xb2, 0x34, 0xbd, 0x4b,
	0xcf, 0xcd, 0x46, 0x0e, 0xbf, 0x04, 0x4a, 0xee, 0x12, 0x7c, 0x02, 0x6d, 0x7f, 0x7a, 0x3d, 0x74,
	0xa2, 0xc4, 0x63, 0x98, 0x98, 0x47, 0xd7, 0x26, 0x8b, 0x42, 0xf4, 0x18, 0xb6, 0x23, 0x1a, 0x4e,
	0x24, 0xd1, 0xb1, 0xe3, 0x26, 0x41, 0xc4, 0x2f, 0x4c, 0x9b, 0x2c, 0x2b, 0x90, 0x01, 0x35, 0x97,
	0x77, 0x2a, 0xee, 0x54, 0x78, 0xe1, 0x1f, 0xc9, 0x5c, 0xd7, 0x04, 0xb6, 0x2f, 0xfa, 0x1a, 0xf3,
	0x1e, 0x93, 0xd4, 0x76, 0xf7, 0x10, 0x5a, 0x79, 0x05, 0x52, 0xa1, 0x74, 0x45, 0x67, 0x32, 0x7a,
	0xb6, 0x44, 0x77, 0xa0, 0x72, 0xe3, 0x4c, 0xa6, 0xe9, 0xb5, 0x16, 0x9b, 0xc3, 0xe2, 0x0b, 0x05,
	0x9f, 0x43, 0x85, 0xfb, 0x41, 0x07, 0x50, 0x8e, 0x43, 0xea, 0xca, 0x76, 0xfd, 0xf7, 0xfd, 0x81,
	0x10, 0x8e, 0x45, 0xbb, 0x50, 0xbf, 0x71, 0x26, 0xde, 0xd8, 0x49, 0x04, 0x73, 0x9d, 0x64, 0x7b,
	0x7c, 0x0e, 0x0d, 0x6e, 0xdc, 0x0f, 0xc6, 0x14, 0x6d, 0x41, 0xd1, 0x1b, 0x73, 0xea, 0x36, 0x29,
	0x7a, 0x63, 0x56, 0xe0, 0x30, 0x88, 0x12, 0x59, 0x43, 0xbe, 0x5e, 0x39, 0xe7, 0x11, 0x94, 0x23,
	0xc7, 0xbd, 0x92, 0xd3, 0x9d, 0xaf, 0xf1, 0x5f, 0x4a, 0xbe, 0x71, 0x59, 0xed, 0x4d, 0xff, 0x32,
	0x60, 0x2f, 0x49, 0x26, 0x90, 0xee, 0xe6, 0x02, 0xd4, 0x85, 0xaa, 0x45, 0x9d, 0x71, 0x76, 0x7f,
	0xd4, 0x7c, 0x92, 0x2c, 0x4e, 0x22, 0xf5, 0xe8, 0x31, 0xd4, 0x89, 0xe8, 0x56, 0xdc, 0x29, 0xf1,
	0xce, 0x2c, 0x63, 0x33, 0x04, 0xc2, 0x50, 0x32, 0x47, 0xa4, 0x53, 0x5e, 0x03, 0x64, 0x4a, 0xfc,
	0xb7, 0x02, 0x3b, 0xf3, 0xa8, 0x7b, 0x34, 0x76, 0x23, 0x2f, 0x4c, 0x0f, 0x5b, 0x3f, 0x77, 0xd8,
	0xd8, 0x9a, 0x15, 0xd6, 0xf4, 0xd9, 0xf5, 0x77, 0x26, 0x69, 0x61, 0xd3, 0x3d, 0xfa, 0x0a, 0xaa,
	0xa2, 0xf1, 0x32, 0xb2, 0xfb, 0x4b, 0xad, 0x12, 0x87, 0x41, 0x1c, 0x12, 0x89, 0x45, 0xdf, 0x02,
	0xe4, 0xce, 0xae, 0x08, 0x75, 0xb9, 0xc9, 0x0b, 0xd5, 0x24, 0x39, 0x0b, 0xfc, 0x43, 0xbe, 0xe8,
	0xc2, 0xc1, 0x68, 0xe6, 0x07, 0xfe, 0xec, 0x7a, 0xe5, 0x6d, 0x59, 0x79, 0xe0, 0xd8, 0x5d, 0x14,
	0xb3, 0x4e, 0x36, 0x59, 0xee, 0xf0, 0xef, 0x0b, 0xc5, 0xc9, 0x85, 0xff, 0xf1, 0xdc, 0xe8, 0x10,
	0xea, 0xb1, 0x08, 0x74, 0x7d, 0xda, 0x0b, 0xf9, 0x90, 0x0c, 0x8f, 0x0d, 0x68, 0xe6, 0xf4, 0xec,
	0x15, 0x61, 0x03, 0xd5, 0xa3, 0xe9, 0x9c, 0x7c, 0x7f, 0xe9, 0x53, 0xf0, 0xc3, 0x3f, 0x14, 0x39,
	0x7a, 0xf3, 0xce, 0x44, 0x74, 0x1d, 0xb8, 0xd3, 0x7b, 0xd5, 0xd7, 0x5e, 0x9a, 0xfa, 0x05, 0x7f,
	0x0e, 0xe5, 0xeb, 0xae, 0x16, 0xd0, 0x7f, 0x60, 0x27, 0xd5, 0x1c, 0x91, 0xc1, 0x69, 0xf6, 0xf0,
	0xab, 0x0a, 0xfa, 0x3f, 0x3c, 0x48, 0x55, 0x3d, 0xe3, 0x58, 0x3b, 0xb3, 0xec, 0x5b, 0x90, 0x22,
	0xe3, 0x1d, 0xd9, 0x9a, 0xbd, 0x64, 0x5c, 0x62, 0x5f, 0x1c, 0xa9, 0x91, 0x94, 0x95, 0xd9, 0x23,
	0x7a, 0xd6, 0x3f, 0xed, 0x0f, 0xce, 0xfb, 0x6a, 0xe5, 0xe0, 0xd7, 0x3a, 0x54, 0x78, 0xb4, 0xe8,
	0x35, 0xb4, 0xf4, 0x88, 0x3a, 0x09, 0xd5, 0x86, 0xe6, 0x29, 0x9d, 0xa1, 0xcf, 0x57, 0xcd, 0x70,
	0x89, 0x08, 0xbd, 0x53, 0x3a, 0x93, 0xd3, 0x7f, 0xf7, 0xd3, 0x0f, 0x03, 0xc3, 0xc9, 0x0c, 0x17,
	0xd0, 0x6b, 0x28, 0xb3, 0x99, 0x8d, 0x1e, 0xad, 0x32, 0x38, 0xa1, 0x49, 0xfe, 0x81, 0x88, 0x53,
	0xf6, 0x2f, 0x36, 0x03, 0x0b, 0x0f, 0x6f, 0xa0, 0x2e, 0x2e, 0xdb, 0x1b, 0x8a, 0x1e, 0x6e, 0x60,
	0x98, 0x3a, 0xe9, 0x6e, 0x84, 0x15, 0x3e, 0x2e, 0xa1, 0x2a, 0x92, 0x43, 0x4f, 0xd6, 0x27, 0xbe,
	0xca, 0xc9, 0xa3, 0x4d, 0xe1, 0x99, 0x9f, 0x1e, 0x9d, 0xd0, 0x75, 0x7e, 0x84, 0x6e, 0x63, 0x3f,
	0xab, 0xe0, 0xc2, 0x4f, 0x0f, 0x20, 0x7b, 0x5c, 0x63, 0xd4, 0x59, 0x3a, 0xe4, 0x29, 0xed, 0xae,
	0xd4, 0xac, 0x78, 0x76, 0x71, 0x01, 0x99, 0xd0, 0x4e, 0x2b, 0x2f, 0x5e, 0x98, 0xf5, 0x44, 0xcb,
	0xf7, 0x28, 0x37, 0x20, 0x71, 0x01, 0x1d, 0x41, 0x53, 0x54, 0xe5, 0x43, 0x44, 0xf7, 0xf2, 0x9a,
	0xfc, 0x47, 0x0a, 0xe7, 0x10, 0x19, 0x7f, 0x1c, 0xc7, 0x59, 0x38, 0xfe, 0xb8, 0x38, 0xbe, 0x81,
	0x1a, 0xab, 0x97, 0xa6, 0x5b, 0x48, 0x9d, 0x7f, 0x66, 0x89, 0xcf, 0xb1, 0xdd, 0x07, 0xb7, 0xec,
	0x16, 0x3f, 0xd4, 0x70, 0x01, 0x3d, 0x87, 0x86, 0xbc, 0x47, 0xba, 0x85, 0x6e, 0x7d, 0xa6, 0xbd,
	0xcf, 0xeb, 0x0b, 0x68, 0x88, 0xec, 0x57, 0xfb, 0x5d, 0x6f, 0xf9, 0xa6, 0xca, 0xff, 0xde, 0x7d,
	0xf9, 0x4f, 0x00, 0x00, 0x00, 0xff, 0xff, 0xd2, 0x43, 0xfc, 0x13, 0x18, 0x0e, 0x00, 0x00,
}
